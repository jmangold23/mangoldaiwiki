<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SHAP on mangoldai :: cloud architect insights :: Joshua Mangold</title>
    <link>https://jmangold23.github.io/mangoldaiwiki/tags/shap/</link>
    <description>Recent content in SHAP on mangoldai :: cloud architect insights :: Joshua Mangold</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://jmangold23.github.io/mangoldaiwiki/tags/shap/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Unified Approach to Interpreting Model Predictions with SHAP</title>
      <link>https://jmangold23.github.io/mangoldaiwiki/posts/unified_approach_to_interpreting_model_predictions_with_shap/</link>
      <pubDate>Sat, 18 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://jmangold23.github.io/mangoldaiwiki/posts/unified_approach_to_interpreting_model_predictions_with_shap/</guid>
      <description>Unified Approach to Interpreting Model Predictions with SHAP In the era of complex and highly accurate machine learning models, a critical challenge has emerged - the tension between model accuracy and interpretability. While advanced models like ensemble methods and deep neural networks can achieve state-of-the-art performance on large, modern datasets, their inner workings often remain opaque, making it difficult for even experts to understand why they make certain predictions.
To address this issue, researchers Scott M.</description>
    </item>
    
    <item>
      <title>Unlocking the Black Box- Interpreting Machine Learning Models with Azure Machine Learning</title>
      <link>https://jmangold23.github.io/mangoldaiwiki/posts/unlocking_the_black_box_interpreting_machine_learning_models_with_azure_machine_learning/</link>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://jmangold23.github.io/mangoldaiwiki/posts/unlocking_the_black_box_interpreting_machine_learning_models_with_azure_machine_learning/</guid>
      <description>Unlocking the Black Box: Interpreting Machine Learning Models with Azure Machine Learning In the world of machine learning, models can often become akin to black boxes - powerful predictive tools that deliver remarkable results, yet their inner workings remain opaque and difficult to understand. This is where model interpretability comes into play, providing invaluable insights that can shape the development, deployment, and governance of your machine learning applications.
Azure Machine Learning offers a comprehensive suite of tools and techniques to help you unravel the mysteries of your models, empowering you to build more transparent, trustworthy, and responsible AI systems.</description>
    </item>
    
  </channel>
</rss>
