<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>model interpretability on Cloud architect insights :: Joshua Mangold</title>
    <link>https://mangoldai.com/tags/model-interpretability/</link>
    <description>Recent content in model interpretability on Cloud architect insights :: Joshua Mangold</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://mangoldai.com/tags/model-interpretability/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Unified Approach to Interpreting Model Predictions with SHAP</title>
      <link>https://mangoldai.com/posts/unified_approach_to_interpreting_model_predictions_with_shap/</link>
      <pubDate>Sat, 18 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://mangoldai.com/posts/unified_approach_to_interpreting_model_predictions_with_shap/</guid>
      <description>Unified Approach to Interpreting Model Predictions with SHAP In the era of complex and highly accurate machine learning models, a critical challenge has emerged - the tension between model accuracy and interpretability. While advanced models like ensemble methods and deep neural networks can achieve state-of-the-art performance on large, modern datasets, their inner workings often remain opaque, making it difficult for even experts to understand why they make certain predictions.
To address this issue, researchers Scott M.</description>
    </item>
    
    <item>
      <title>Unlocking the Black Box- Interpreting Machine Learning Models with Azure Machine Learning</title>
      <link>https://mangoldai.com/posts/unlocking_the_black_box_interpreting_machine_learning_models_with_azure_machine_learning/</link>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mangoldai.com/posts/unlocking_the_black_box_interpreting_machine_learning_models_with_azure_machine_learning/</guid>
      <description>Unlocking the Black Box: Interpreting Machine Learning Models with Azure Machine Learning In the world of machine learning, models can often become akin to black boxes - powerful predictive tools that deliver remarkable results, yet their inner workings remain opaque and difficult to understand. This is where model interpretability comes into play, providing invaluable insights that can shape the development, deployment, and governance of your machine learning applications.
Azure Machine Learning offers a comprehensive suite of tools and techniques to help you unravel the mysteries of your models, empowering you to build more transparent, trustworthy, and responsible AI systems.</description>
    </item>
    
    <item>
      <title>Unraveling Machine Learning Models with InterpretML</title>
      <link>https://mangoldai.com/posts/unraveling_machine_learning_models_with_interpretml/</link>
      <pubDate>Wed, 20 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mangoldai.com/posts/unraveling_machine_learning_models_with_interpretml/</guid>
      <description>Unraveling Machine Learning Models with InterpretML In the world of modern machine learning, models have become increasingly complex, often operating as opaque &amp;ldquo;black boxes&amp;rdquo; that deliver impressive results but leave us wondering about the inner workings that drive their decision-making. This poses a significant challenge, as understanding model behavior is crucial for building trust, debugging issues, and ensuring responsible AI deployment.
Enter InterpretML, an open-source toolkit that empowers data scientists, developers, and business stakeholders to gain comprehensive insights into their machine learning models.</description>
    </item>
    
  </channel>
</rss>
